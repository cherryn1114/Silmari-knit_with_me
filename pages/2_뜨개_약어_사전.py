# pages/2_ëœ¨ê°œ_ì•½ì–´_ì‚¬ì „.py
# ê°œë³„ ì˜ìƒ ë§í¬ 1ê°œ(í•œêµ­ì–´ ìš°ì„ ) + ì •í™•ë„ ê°•í™” + ì˜¤ë²„ë¼ì´ë“œ í¸ì§‘/ì €ì¥

import os, re, json
import pandas as pd
import streamlit as st
from lib import parser

st.set_page_config(page_title="ğŸ“˜ ëœ¨ê°œ ì•½ì–´ ì‚¬ì „", page_icon="ğŸ“˜", layout="wide")
st.title("ğŸ“˜ ëœ¨ê°œ ì•½ì–´ ì‚¬ì „")
st.caption("ì‚¬ì§„ ì† ëª¨ë“  ì•½ì–´ê°€ í¬í•¨ë©ë‹ˆë‹¤. ê° í•­ëª©ì— **ê°œë³„ ì˜ìƒ 1ê°œ(í•œêµ­ì–´ ìš°ì„ )**ê°€ í•˜ì´í¼ë§í¬ë¡œ ë¶™ìŠµë‹ˆë‹¤. ì˜ëª» ë§¤ì¹­ëœ ê²½ìš° ìš°ì¸¡ â€˜ê²€ìˆ˜/ìˆ˜ì •â€™ì—ì„œ ë°”ë¡œ ê³ ì³ ì €ì¥í•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •
OVERRIDE_PATH = "lib/video_overrides.json"
DEFAULT_PLAYLISTS = [
    "https://youtube.com/playlist?list=PLp5XrSgnenszb2E_yfQ-X2KFwHsUhRTyJ",
    "https://youtube.com/playlist?list=PLtqSRloqJqzodilL7rTKkd6BwS8RvVpTq",
]

# ì‚¬ì§„ ê¸°ë°˜ í•„ìˆ˜/ê¸ˆì§€ í‚¤ì›Œë“œ ê·œì¹™(ì •í™•ë„ ê°•í™”)
MUST = {
    "1x1 rib": ["1x1", "rib"],
    "2x2 rib": ["2x2", "rib"],
    "garter": ["garter"],
    "stockinette": ["stockinette", "stocking", "st st", "st-st"],
    "k2tog": ["k2tog"],
    "p2tog": ["p2tog"],
    "ssk": ["ssk", "skp"],
    "ssp": ["ssp"],
    "m1l": ["m1l", "make 1 left"],
    "m1r": ["m1r", "make 1 right"],
    "yo": ["yarn over", "yo"],
    "ktbl": ["ktbl", "through the back loop", "tbl"],
    "ptbl": ["ptbl", "purl tbl", "through the back loop"],
    "cast on": ["cast on"],
    "bind off": ["bind off", "cast off"],
    "pick up": ["pick up"],
    "cable": ["cable"],
    "right cross": ["right cross", "rc"],
    "left cross": ["left cross", "lc"],
    "marker": ["stitch marker", "place marker", "slip marker", "pm", "sm"],
    "yarn front": ["yarn in front", "yfwd", "wyif"],
    "yarn back":  ["yarn in back", "ybk", "wyib"],
    "gauge": ["gauge"],
}
FORBID = {
    # ì˜ˆ: ribì—ì„œ yarn over ê°€ ë“¤ì–´ê°„ ì˜ìƒì€ ê°ì /íƒˆë½
    "1x1 rib": ["yarn over", "yo"],
    "2x2 rib": ["yarn over", "yo"],
    "garter": ["yarn over"],
    "stockinette": ["yarn over"],
    "k2tog": ["ssk", "ssp", "m1", "yarn over"],
    "p2tog": ["ssk", "ssp", "m1", "yarn over"],
    "ssk": ["k2tog", "m1", "yarn over"],
    "ssp": ["k2tog", "m1", "yarn over"],
    "m1l": ["k2tog", "ssk", "bind off"],
    "m1r": ["k2tog", "ssk", "bind off"],
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ + ì „ì²´ í–‰ ë³€í™˜
LIB = parser.load_lib("symbols.json")
rows = []
for key, v in LIB.items():
    rows.append({
        "key": key,
        "ì•½ì(ì•½ì–´)": key,
        "ìš©ì–´(ì˜ë¬¸)": v.get("name_en",""),
        "í•œêµ­ì–´": v.get("name_ko",""),
        "ì„¤ëª…": v.get("desc_ko",""),
        "aliases": [key] + v.get("aliases", []),
    })
base_df = pd.DataFrame(rows)

def norm(s): return (s or "").strip().lower()
base_df["_idx"] = (
    base_df["ì•½ì(ì•½ì–´)"].apply(norm) + " " +
    base_df["ìš©ì–´(ì˜ë¬¸)"].apply(norm) + " " +
    base_df["í•œêµ­ì–´"].apply(norm) + " " +
    base_df["aliases"].apply(lambda a: " ".join(norm(x) for x in a))
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜¤ë²„ë¼ì´ë“œ ë¡œë“œ/ì €ì¥
def load_overrides(path: str) -> dict:
    if not os.path.exists(path):
        return {}
    try:
        return json.loads(open(path, encoding="utf-8").read())
    except Exception:
        return {}

def save_overrides(path: str, data: dict):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

OVR = load_overrides(OVERRIDE_PATH)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¬ìƒëª©ë¡ì—ì„œ ì˜ìƒ ìˆ˜ì§‘
with st.sidebar:
    st.subheader("ğŸ¥ ìœ íŠœë¸Œ ì¬ìƒëª©ë¡")
    pls = st.text_area("í•œ ì¤„ì— í•˜ë‚˜ì”©", value="\n".join(DEFAULT_PLAYLISTS), height=90).strip().splitlines()
    fetch_btn = st.button("ì¬ìƒëª©ë¡ì—ì„œ ì˜ìƒ ë¶ˆëŸ¬ì˜¤ê¸° / ê°±ì‹ ")
    reload_dict = st.button("ğŸ” ìš©ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ì‹œ ë¡œë“œ")
    if reload_dict:
        parser._LIB = None
        parser._ALL_KEYS = None
        st.experimental_rerun()

@st.cache_data(show_spinner=True, ttl=60*60)
def fetch_videos_from_playlists(playlists: list[str]) -> pd.DataFrame:
    try:
        import yt_dlp
    except Exception:
        st.warning("yt-dlpê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirements.txtì— 'yt-dlp' ì¶”ê°€ í›„ ì¬ì‹¤í–‰í•˜ì„¸ìš”.")
        return pd.DataFrame(columns=["title","url","lower","has_korean"])
    vids = []
    ydl_opts = {"quiet": True, "extract_flat": True, "skip_download": True}
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        for pl in playlists:
            try:
                info = ydl.extract_info(pl, download=False)
                for e in (info or {}).get("entries", []) or []:
                    url = e.get("webpage_url") or e.get("url") or ""
                    if url and not url.startswith("http"):
                        url = f"https://www.youtube.com/watch?v={url}"
                    title = (e.get("title") or "").strip()
                    if not (url and title): 
                        continue
                    lower = title.lower()
                    has_korean = bool(re.search(r"[ê°€-í£]", title))
                    vids.append({"title": title, "url": url, "lower": lower, "has_korean": has_korean})
            except Exception as ex:
                st.warning(f"ì¬ìƒëª©ë¡ ì½ê¸° ì‹¤íŒ¨: {pl}\n{ex}")
    return pd.DataFrame(vids).drop_duplicates(subset=["url"])

video_df = fetch_videos_from_playlists(pls) if fetch_btn or "video_df" not in st.session_state else st.session_state["video_df"]
st.session_state["video_df"] = video_df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤ì½”ì–´ëŸ¬(ì •í™•ë„ ê°•í™”)
def choose_one_video(row, videos: pd.DataFrame, overrides: dict) -> tuple[str, list[dict]]:
    """ì˜¤ë²„ë¼ì´ë“œ > ìŠ¤ì½”ì–´ ê¸°ë°˜ ì„ íƒ(í•œêµ­ì–´ ìš°ì„ ) / í›„ë³´ëª©ë¡ ë°˜í™˜"""
    key = row["key"]
    # 1) ì˜¤ë²„ë¼ì´ë“œê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
    if overrides.get(key):
        return overrides[key], []

    if videos is None or videos.empty:
        return "", []

    # í‚¤ì›Œë“œ ì„¸íŠ¸
    words = set()
    words.add(norm(row["ì•½ì(ì•½ì–´)"]))
    words.update(norm(a) for a in row["aliases"])
    words.update(w for w in re.split(r"[ /(),\-]+", norm(row["ìš©ì–´(ì˜ë¬¸)"])) if w)
    words = {w for w in words if w and len(w) >= 2}

    # í•„ìˆ˜/ê¸ˆì§€
    must = set()
    forbid = set()
    for k, mlist in MUST.items():
        if k in words:
            must.update(mlist)
    for k, flist in FORBID.items():
        if k in words:
            forbid.update(flist)
    must = {m.lower() for m in must}
    forbid = {f.lower() for f in forbid}

    def score_row(vrow) -> int:
        t = vrow["lower"]
        # í•„ìˆ˜ í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ íƒˆë½
        if must and not any(m in t for m in must):
            return -999
        s = 0
        # ì •í™•ë„ ê°€ì¤‘ì¹˜
        s += sum(3 for w in words if f" {w} " in f" {t} ")       # ì™„ì „ì–´ ë§¤ì¹˜
        s += sum(1 for w in words if w in t)                     # ë¶€ë¶„ì–´ ë§¤ì¹˜
        s -= sum(3 for w in forbid if w in t)                    # ê¸ˆì§€ í‚¤ì›Œë“œ ê°ì 
        # ì–¸ì–´ ê°€ì¤‘ì¹˜: í•œêµ­ì–´ ìš°ì„ 
        s += 2 if vrow.get("has_korean") else 0
        return s

    scored = []
    for _, v in videos.iterrows():
        sc = score_row(v)
        if sc > 0:
            scored.append((sc, v["title"], v["url"]))
    scored.sort(key=lambda x: (-x[0], x[1]))
    top = scored[0][2] if scored else ""
    # í›„ë³´ ìƒìœ„ 8ê°œ(ê²€ìˆ˜ìš©)
    cand = [{"title": t, "url": u, "score": s} for s, t, u in scored[:8]]
    return top, cand

# ë§¤ì¹­/í›„ë³´ ìˆ˜ì§‘
selected_links, candidates = [], {}
for _, r in base_df.iterrows():
    link, cand = choose_one_video(r, video_df, OVR)
    selected_links.append(link)
    candidates[r["key"]] = cand

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²€ìƒ‰ + í‘œ(í•˜ì´í¼ë§í¬) ë Œë”ë§
table_df = base_df[["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…"]].copy()
table_df["ì˜ìƒ"] = selected_links

c1, c2 = st.columns([2,1])
with c1:
    q = st.text_input("ê²€ìƒ‰(ì˜ˆ: m1l / cast on / ê²‰ëœ¨ê¸° / ê²Œì´ì§€)", "")
with c2:
    only_with_video = st.checkbox("ì˜ìƒ ìˆëŠ” ê²ƒë§Œ", value=False)

fdf = table_df.copy()
if q.strip():
    key = norm(q)
    fdf = fdf[base_df["_idx"].str.contains(key)].copy()
if only_with_video:
    fdf = fdf[fdf["ì˜ìƒ"].astype(str).str.startswith("http")]

st.caption(f"ì´ ìš©ì–´: **{len(table_df)}** Â· í‘œì‹œ: **{len(fdf)}**")
st.data_editor(
    fdf[["ì•½ì(ì•½ì–´)","ìš©ì–´(ì˜ë¬¸)","í•œêµ­ì–´","ì„¤ëª…","ì˜ìƒ"]],
    use_container_width=True,
    hide_index=True,
    disabled=True,
    column_config={
        "ì˜ìƒ": st.column_config.LinkColumn("ì˜ìƒ", display_text="ì—´ê¸°", max_chars=300)
    },
    num_rows="fixed",
    height=min(120 + len(fdf)*34, 5000),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²€ìˆ˜/ìˆ˜ì • ëª¨ë“œ: ì˜¤ë²„ë¼ì´ë“œ ì €ì¥
st.markdown("---")
st.subheader("ğŸ›  ê²€ìˆ˜/ìˆ˜ì • (ì˜¤ë²„ë¼ì´ë“œ)")
st.caption("ì˜ëª» ë§¤ì¹­ëœ í•­ëª©ì€ ì—¬ê¸°ì„œ ì›í•˜ëŠ” ì˜ìƒì„ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ URLì„ ë¶™ì—¬ ë„£ê³  â€˜ì €ì¥â€™í•˜ì„¸ìš”. ì €ì¥í•˜ë©´ ë‹¤ìŒë¶€í„°ëŠ” ìë™ìœ¼ë¡œ ì´ ë§í¬ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.")

edited = False
for _, row in base_df.iterrows():
    k = row["key"]
    with st.expander(f"{row['ì•½ì(ì•½ì–´)']} Â· {row['ìš©ì–´(ì˜ë¬¸)']} Â· {row['í•œêµ­ì–´']}"):
        current = OVR.get(k, selected_links[_])
        st.write("í˜„ì¬ ë§í¬:", current or "ì—†ìŒ")
        opts = candidates.get(k, [])
        titles = [f"[{c['score']}] {c['title']}" for c in opts]
        urls = [c["url"] for c in opts]
        pick = st.selectbox("í›„ë³´ì—ì„œ ì„ íƒ", ["(ì„ íƒ ì•ˆ í•¨)"] + titles, index=0, key=f"pick_{k}")
        manual = st.text_input("ì§ì ‘ URL ì…ë ¥(ë¶™ì—¬ë„£ê¸°)", value=current or "", key=f"manual_{k}")
        col1, col2 = st.columns([1,1])
        with col1:
            if st.button("ì´ í•­ëª© ì €ì¥", key=f"save_{k}"):
                new_url = ""
                if pick != "(ì„ íƒ ì•ˆ í•¨)":
                    new_url = urls[titles.index(pick)]
                if manual.strip().startswith("http"):
                    new_url = manual.strip()
                if new_url:
                    OVR[k] = new_url
                elif k in OVR:   # ë¹„ìš°ê³  ì‹¶ìœ¼ë©´ ì‚­ì œ
                    del OVR[k]
                save_overrides(OVERRIDE_PATH, OVR)
                edited = True
        with col2:
            if st.button("ì˜¤ë²„ë¼ì´ë“œ ì œê±°", key=f"del_{k}"):
                if k in OVR:
                    del OVR[k]
                    save_overrides(OVERRIDE_PATH, OVR)
                    edited = True

if edited:
    st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ í‘œê°€ ìƒˆ ë§í¬ë¡œ ê°±ì‹ ë©ë‹ˆë‹¤.")
    st.experimental_rerun()