# pages/2_ëœ¨ê°œ_ì•½ì–´_ì‚¬ì „.py
# í‘œ í˜•ì‹ + ê°œë³„ ì˜ìƒ í•˜ì´í¼ë§í¬(í´ë¦­ ì¦‰ì‹œ ì´ë™)
import re
import pandas as pd
import streamlit as st
from lib import parser

st.set_page_config(page_title="ğŸ“˜ ëœ¨ê°œ ì•½ì–´ ì‚¬ì „", page_icon="ğŸ“˜", layout="wide")
st.title("ğŸ“˜ ëœ¨ê°œ ì•½ì–´ ì‚¬ì „")
st.caption("ì˜ë¬¸ ì•½ì–´/ì˜ë¬¸ ìš©ì–´/í•œê¸€ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”. ê° í•­ëª©ì— ê´€ë ¨ **ê°œë³„ ì˜ìƒ ë§í¬**ê°€ í‘œì— ë“¤ì–´ê°‘ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) ì˜ìƒ ì†ŒìŠ¤(ìœ íŠœë¸Œ ì¬ìƒëª©ë¡)
DEFAULT_PLAYLISTS = [
    "https://youtube.com/playlist?list=PLp5XrSgnenszb2E_yfQ-X2KFwHsUhRTyJ",
    "https://youtube.com/playlist?list=PLtqSRloqJqzodilL7rTKkd6BwS8RvVpTq",
]
with st.sidebar:
    st.subheader("ğŸ¥ ìœ íŠœë¸Œ ì¬ìƒëª©ë¡")
    pls = st.text_area(
        "í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥",
        value="\n".join(DEFAULT_PLAYLISTS),
        height=100,
        placeholder="https://youtube.com/playlist?list=XXXX\nhttps://youtube.com/playlist?list=YYYY",
    ).strip().splitlines()
    fetch_btn = st.button("ì¬ìƒëª©ë¡ì—ì„œ ì˜ìƒ ë¶ˆëŸ¬ì˜¤ê¸° / ì—…ë°ì´íŠ¸")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ì•½ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ (ì‚¬ì§„ ì† ëª¨ë“  ì•½ì–´ëŠ” lib/symbols.jsonì— ë“¤ì–´ìˆì–´ì•¼ í•¨)
LIB = parser.load_lib("symbols.json")   # ì£¼ì˜: "lib/..." ë§ê³  íŒŒì¼ëª…ë§Œ!
rows = []
for key, v in LIB.items():
    rows.append({
        "ì•½ì(ì•½ì–´)": key,
        "ìš©ì–´(ì˜ë¬¸)": v.get("name_en", ""),
        "í•œêµ­ì–´": v.get("name_ko", ""),
        "ì„¤ëª…": v.get("desc_ko", ""),
        "aliases": [key] + v.get("aliases", []),
    })
base_df = pd.DataFrame(rows)

def norm(s): return (s or "").strip().lower()
base_df["_idx"] = (
    base_df["ì•½ì(ì•½ì–´)"].apply(norm) + " " +
    base_df["ìš©ì–´(ì˜ë¬¸)"].apply(norm) + " " +
    base_df["í•œêµ­ì–´"].apply(norm) + " " +
    base_df["aliases"].apply(lambda a: " ".join(norm(x) for x in a))
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) yt-dlpë¡œ ì¬ìƒëª©ë¡ì˜ ê°œë³„ ì˜ìƒ ì œëª©/ë§í¬ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ)
@st.cache_data(show_spinner=True, ttl=60*60)
def fetch_videos_from_playlists(playlists: list[str]) -> pd.DataFrame:
    try:
        import yt_dlp  # pip install yt-dlp
    except Exception:
        st.warning("yt-dlpê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirements.txtì— 'yt-dlp' ì¶”ê°€ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return pd.DataFrame(columns=["title", "url", "lower"])
    vids = []
    ydl_opts = {"quiet": True, "extract_flat": True, "skip_download": True}
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        for pl in playlists:
            try:
                info = ydl.extract_info(pl, download=False)
                for e in (info or {}).get("entries", []) or []:
                    url = e.get("webpage_url") or e.get("url") or ""
                    if url and not url.startswith("http"):
                        url = f"https://www.youtube.com/watch?v={url}"
                    title = e.get("title") or ""
                    if url and title:
                        vids.append({"title": title, "url": url, "lower": title.lower()})
            except Exception as ex:
                st.warning(f"ì¬ìƒëª©ë¡ ì½ê¸° ì‹¤íŒ¨: {pl}\n{ex}")
    df = pd.DataFrame(vids).drop_duplicates(subset=["url"])
    return df

video_df = fetch_videos_from_playlists(pls) if fetch_btn or "video_df" not in st.session_state else st.session_state["video_df"]
st.session_state["video_df"] = video_df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ì˜ìƒ ë§¤ì¹­ ê·œì¹™ (ì œëª©ì— ì•½ì–´/ë™ì˜ì–´/ì˜ë¬¸ëª… í‚¤ì›Œë“œê°€ ë“¤ì–´ê°€ë©´ ë§¤ì¹­)
BOOST = {
    # ëŒ€í‘œ ì¦ê°€/ê°ì†Œ/ê¸°ë³¸
    "k2tog": ["k2tog"],
    "p2tog": ["p2tog"],
    "ssk": ["ssk", "skp"],  # ì˜ìƒì´ SKPë¡œ ì˜¬ë¼ê°„ ê²½ìš° ì»¤ë²„
    "ssp": ["ssp"],
    "m1l": ["m1l", "make 1 left"],
    "m1r": ["m1r", "make 1 right"],
    "yo": ["yo", "yarn over"],
    "ktbl": ["ktbl", "tbl", "through the back loop"],
    "ptbl": ["ptbl", "purl tbl", "through the back loop"],
    "garter": ["garter"],
    "stockinette": ["stockinette", "stocking", "st st"],
    "rib": ["rib", "1x1 rib", "2x2 rib", "r-st"],
    "gauge": ["gauge"],
    "cast on": ["cast on", "co", "long tail cast on", "backward loop"],
    "bind off": ["bind off", "cast off", "bo"],
    "pick up": ["pick up"],
    "cable": ["cable", "left cross", "right cross", "lc", "rc"],
    "slip": ["slip", "sl wyif", "sl wyib", "slip knitwise", "slip purlwise"],
    "marker": ["stitch marker", "place marker", "slip marker", "pm", "sm"],
    "yarn front": ["yarn in front", "wyif", "yfwd"],
    "yarn back": ["yarn in back", "wyib", "ybk"],
}

def collect_matches(row, videos: pd.DataFrame, topk=3):
    if videos.empty: return ["", "", ""]
    keys = set()
    keys.add(norm(row["ì•½ì(ì•½ì–´)"]))
    keys.update(norm(a) for a in row["aliases"])
    keys.update(w for w in re.split(r"[ /(),\-]+", norm(row["ìš©ì–´(ì˜ë¬¸)"])) if w)

    # ë³´ì • í‚¤ì›Œë“œ ì£¼ì…
    for k, boosts in BOOST.items():
        if k in keys or any(k in t for t in keys):
            keys.update(boosts)

    keys = {k for k in keys if k and len(k) >= 2}

    def score(title_lower: str) -> int:
        return sum(1 for k in keys if k in title_lower)

    scored = []
    for _, v in videos.iterrows():
        s = score(v["lower"])
        if s > 0:
            scored.append((s, v["title"], v["url"]))
    scored.sort(key=lambda x: (-x[0], x[1]))
    out = [u for _, _, u in scored[:topk]]
    # í•­ìƒ 3ì¹¸ ìœ ì§€
    while len(out) < topk: out.append("")
    return out[:topk]

# ë§¤ì¹­ ìˆ˜í–‰
video1, video2, video3 = [], [], []
if not video_df.empty:
    for _, r in base_df.iterrows():
        v1, v2, v3 = collect_matches(r, video_df, topk=3)
        video1.append(v1); video2.append(v2); video3.append(v3)
else:
    video1 = [""]*len(base_df); video2 = [""]*len(base_df); video3 = [""]*len(base_df)

# í‘œ ë°ì´í„° êµ¬ì„± (í•˜ì´í¼ë§í¬ ì»¬ëŸ¼ 3ê°œ)
table_df = base_df[["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…"]].copy()
table_df["ì˜ìƒ1"] = video1
table_df["ì˜ìƒ2"] = video2
table_df["ì˜ìƒ3"] = video3

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ê²€ìƒ‰ â†’ í‘œ ë Œë”ë§(ë§í¬ í´ë¦­ ê°€ëŠ¥)
c1, c2 = st.columns([2,1])
with c1:
    q = st.text_input("ê²€ìƒ‰ (ì˜ˆ: m1l / cast on / ê²‰ëœ¨ê¸° / ê²Œì´ì§€ ë“±)", "")
with c2:
    show_cols = st.multiselect(
        "í‘œì‹œí•  ì—´",
        ["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…", "ì˜ìƒ1", "ì˜ìƒ2", "ì˜ìƒ3"],
        default=["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…", "ì˜ìƒ1", "ì˜ìƒ2", "ì˜ìƒ3"]
    )

fdf = table_df.copy()
if q.strip():
    key = norm(q)
    idx = base_df["_idx"].str.contains(key)
    fdf = fdf[idx].copy()

# Streamlitì˜ data_editor + LinkColumn ìœ¼ë¡œ "í´ë¦­ ê°€ëŠ¥í•œ ë§í¬" í‘œ êµ¬í˜„
link_cols = {}
for col in ["ì˜ìƒ1", "ì˜ìƒ2", "ì˜ìƒ3"]:
    link_cols[col] = st.column_config.LinkColumn(
        col, help="ì˜ìƒ ë§í¬", validate="^https?://.*", max_chars=300, display_text="ì—´ê¸°"
    )

st.data_editor(
    fdf[show_cols],
    use_container_width=True,
    hide_index=True,
    disabled=True,  # ë³´ê¸° ì „ìš©
    column_config=link_cols,
    num_rows="fixed",
)

st.caption("â€» ë§í¬ëŠ” ì œê³µëœ ìœ íŠœë¸Œ ì¬ìƒëª©ë¡ì˜ **ê°œë³„ ì˜ìƒ**ì„ ì œëª©-í‚¤ì›Œë“œë¡œ ë§¤ì¹­í•´ ìë™ ë¶€ì—¬ë©ë‹ˆë‹¤. í•„ìš” ì‹œ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ìƒëª©ë¡ì„ ë°”ê¾¸ê³  â€˜ë¶ˆëŸ¬ì˜¤ê¸°â€™ë¥¼ ëˆŒëŸ¬ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")