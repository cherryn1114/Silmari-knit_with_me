# pages/2_ëœ¨ê°œ_ì•½ì–´_ì‚¬ì „.py
import re
import streamlit as st
import pandas as pd
from lib import parser

st.set_page_config(page_title="ğŸ“˜ ëœ¨ê°œ ì•½ì–´ ì‚¬ì „", page_icon="ğŸ“˜", layout="wide")
st.title("ğŸ“˜ ëœ¨ê°œ ì•½ì–´ ì‚¬ì „")
st.caption("ì˜ë¬¸ ì•½ì–´/ì˜ë¬¸ ìš©ì–´/í•œê¸€ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”. í‘œì˜ â€˜ì˜ìƒ1/2/3â€™ì€ **ê°œë³„ ì˜ìƒ ë§í¬**ì´ë©° í´ë¦­ ì¦‰ì‹œ ì´ë™í•©ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) ê¸°ë³¸ ì¬ìƒëª©ë¡(ë„ˆê°€ ì¤€ 2ê°œ)
DEFAULT_PLAYLISTS = [
    "https://youtube.com/playlist?list=PLp5XrSgnenszb2E_yfQ-X2KFwHsUhRTyJ",
    "https://youtube.com/playlist?list=PLtqSRloqJqzodilL7rTKkd6BwS8RvVpTq",
]

with st.sidebar:
    st.subheader("ğŸ¥ ì˜ìƒ ì†ŒìŠ¤(YouTube ì¬ìƒëª©ë¡)")
    playlists = st.text_area(
        "í•œ ì¤„ì— í•˜ë‚˜ì”© ì¬ìƒëª©ë¡ URL",
        value="\n".join(DEFAULT_PLAYLISTS),
        placeholder="https://youtube.com/playlist?list=XXXX\nhttps://youtube.com/playlist?list=YYYY",
        height=100,
    ).strip().splitlines()
    fetch_btn = st.button("ì¬ìƒëª©ë¡ì—ì„œ ì˜ìƒ ë¶ˆëŸ¬ì˜¤ê¸°/ì—…ë°ì´íŠ¸")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ìš©ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ (ì‚¬ì§„ ì† ëª¨ë“  ì•½ì–´ëŠ” lib/symbols.jsonì— ì´ë¯¸ í¬í•¨ë¼ ìˆì–´ì•¼ í•¨)
LIB = parser.load_lib("symbols.json")   # ì£¼ì˜: "lib/..." ë§ê³  "symbols.json"ë§Œ!
rows = []
for key, v in LIB.items():
    rows.append({
        "key": key,
        "ì•½ì(ì•½ì–´)": key,
        "ìš©ì–´(ì˜ë¬¸)": v.get("name_en",""),
        "í•œêµ­ì–´": v.get("name_ko",""),
        "ì„¤ëª…": v.get("desc_ko",""),
        "aliases": [key] + v.get("aliases", []),
    })
base_df = pd.DataFrame(rows)

# ê²€ìƒ‰ ì¸ë±ìŠ¤
def norm(s): return (s or "").strip().lower()
base_df["_idx"] = (
    base_df["ì•½ì(ì•½ì–´)"].apply(norm) + " " +
    base_df["ìš©ì–´(ì˜ë¬¸)"].apply(norm) + " " +
    base_df["í•œêµ­ì–´"].apply(norm) + " " +
    base_df["aliases"].apply(lambda a: " ".join([norm(x) for x in a]))
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì¬ìƒëª©ë¡ ê°œë³„ ì˜ìƒ ë©”íƒ€ ìˆ˜ì§‘ (yt-dlp)
@st.cache_data(show_spinner=True, ttl=60*60)
def fetch_videos_from_playlists(playlists: list[str]) -> pd.DataFrame:
    """
    playlists: ì¬ìƒëª©ë¡ URL ë¦¬ìŠ¤íŠ¸
    return: DataFrame[title,url,lower]
    """
    try:
        import yt_dlp  # pip install yt-dlp
    except Exception:
        st.warning("yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ `pip install yt-dlp` ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return pd.DataFrame(columns=["title","url","lower"])

    vids: list[dict] = []
    ydl_opts = {
        "quiet": True,
        "extract_flat": True,  # ë¹ ë¥´ê²Œ ë©”íƒ€ë°ì´í„°ë§Œ
        "skip_download": True,
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        for pl in playlists:
            try:
                info = ydl.extract_info(pl, download=False)
                entries = info.get("entries", []) if info else []
                for e in entries:
                    # ì¼ë¶€ í•­ëª©ì€ 'url'ì— ë¹„ë””ì˜¤ IDë§Œ ë“¤ì–´ì˜¤ë¯€ë¡œ ë³´ì •
                    vid_url = e.get("url") or e.get("webpage_url") or ""
                    if vid_url and not vid_url.startswith("http"):
                        vid_url = f"https://www.youtube.com/watch?v={vid_url}"
                    title = (e.get("title") or "").strip()
                    if vid_url and title:
                        vids.append({"title": title, "url": vid_url, "lower": title.lower()})
            except Exception as ex:
                st.warning(f"ì¬ìƒëª©ë¡ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {pl}\n{ex}")

    df = pd.DataFrame(vids).drop_duplicates(subset=["url"])
    return df

# ìµœì´ˆ/ì—…ë°ì´íŠ¸ ë¡œë“œ
if fetch_btn or "video_df" not in st.session_state:
    st.session_state["video_df"] = fetch_videos_from_playlists(playlists)
video_df = st.session_state["video_df"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ì•½ì–´-ì˜ìƒ ì œëª© ë§¤ì¹­ ê·œì¹™
BOOST = {
    # ëŠ˜ë¦¼/ì¤„ì„/ê¸°ë³¸ê¸°
    "k2tog": ["k2tog"],
    "p2tog": ["p2tog"],
    "ssk": ["ssk", "skp"],
    "ssp": ["ssp"],
    "m1l": ["m1l", "make 1 left", "left increase"],
    "m1r": ["m1r", "make 1 right", "right increase"],
    "yo": ["yo", "yarn over"],

    # ê¼¬ì•„ëœ¨ê¸°/ë’¤ë‹¤ë¦¬
    "ktbl": ["ktbl", "tbl", "through the back loop"],
    "ptbl": ["ptbl", "purl tbl", "through the back loop"],

    # ì¡°ì§/ê¸°ë³¸ë¬´ëŠ¬
    "garter": ["garter"],
    "stockinette": ["stockinette", "stocking"],
    "rib": ["rib", "1x1 rib", "2x2 rib"],

    # ê¸°íƒ€
    "gauge": ["gauge"],
    "cast on": ["cast on", "co", "long tail cast on", "backward loop"],
    "bind off": ["bind off", "cast off", "bo"],
    "pick up": ["pick up"],
    "cable": ["cable", "left cross", "right cross", "lc", "rc"],
    "slip": ["slip", "sl wyif", "sl wyib", "slip knitwise", "slip purlwise"],
    "marker": ["stitch marker", "place marker", "slip marker", "pm", "sm"],
    "yarn front": ["yarn in front", "wyif", "yfwd"],
    "yarn back": ["yarn in back", "wyib", "ybk"],
}

def collect_matches(row, videos: pd.DataFrame, topk=3):
    """ì•½ì–´/ë™ì˜ì–´/ì˜ë¬¸/í•œê¸€ í‚¤ì›Œë“œë¡œ ì˜ìƒ ì œëª©ì„ ìŠ¤ì½”ì–´ë§í•´ ìƒìœ„ topk ë°˜í™˜"""
    if videos.empty:
        return []
    keys = set()
    keys.add(norm(row["ì•½ì(ì•½ì–´)"]))
    keys.update([w for w in re.split(r"[ /(),-]+", row["ìš©ì–´(ì˜ë¬¸)"].lower()) if w])
    keys.update([norm(a) for a in row["aliases"]])
    # í•œê¸€ ì£¼ìš”ì–´ë„ í•©ì¹˜ê¸° (ê°„ë‹¨ ì„ íƒ)
    for k in ["ëŠ˜ë¦¬", "ì¤„ì´", "ê²‰ëœ¨", "ì•ˆëœ¨", "ê½ˆë°°", "êµì°¨", "ë§ˆì»¤", "ê²Œì´ì§€"]:
        if k in row["í•œêµ­ì–´"]:
            # ëŒ€ì‘ ì˜ë¬¸ í‚¤ì›Œë“œ ì¶”ê°€
            if k == "ëŠ˜ë¦¬": keys.update(["increase", "m1", "inc"])
            if k == "ì¤„ì´": keys.update(["decrease", "dec", "tog"])
            if k == "ê²‰ëœ¨": keys.update(["knit"])
            if k == "ì•ˆëœ¨": keys.update(["purl"])
            if k == "ê½ˆë°°" or k == "êµì°¨": keys.update(["cable", "cross"])
            if k == "ë§ˆì»¤": keys.update(["marker"])
            if k == "ê²Œì´ì§€": keys.update(["gauge"])

    # ë³´ì • ì‚¬ì „
    for bkey, boosts in BOOST.items():
        if any(bkey in k for k in keys):
            keys.update(boosts)

    keys = [k for k in keys if k and len(k) >= 2]

    def score(title_lower: str) -> int:
        return sum(1 for k in keys if k in title_lower)

    scored = []
    for _, v in videos.iterrows():
        s = score(v["lower"])
        if s > 0:
            scored.append((s, v["title"], v["url"]))
    scored.sort(key=lambda x: (-x[0], x[1]))
    top = scored[:topk]
    return [{"title": t, "url": u} for _, t, u in top]

# ë§¤ì¹­ ì‹¤í–‰
df = base_df.copy()
if not video_df.empty:
    df["matches"] = df.apply(lambda r: collect_matches(r, video_df), axis=1)
else:
    df["matches"] = [[] for _ in range(len(df))]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ê²€ìƒ‰ + í‘œ(í´ë¦­ ê°€ëŠ¥í•œ í•˜ì´í¼ë§í¬) êµ¬ì„±
c1, c2 = st.columns([2,1])
with c1:
    q = st.text_input("ê²€ìƒ‰ (ì˜ˆ: m1l / cast on / ê²‰ëœ¨ê¸° / ê²Œì´ì§€ ë“±)", "")
with c2:
    show_cols = st.multiselect(
        "í‘œì‹œí•  ì—´",
        ["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…", "ì˜ìƒ1", "ì˜ìƒ2", "ì˜ìƒ3"],
        default=["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…", "ì˜ìƒ1", "ì˜ìƒ2", "ì˜ìƒ3"]
    )

f = df.copy()
if q.strip():
    key = norm(q)
    f = f[f["_idx"].str.contains(key)]

# ì˜ìƒ ë§í¬ ì»¬ëŸ¼ 3ê°œ ìƒì„± (ê°œë³„ ì˜ìƒ í•˜ì´í¼ë§í¬)
def nth_link(vlist, n):
    if not vlist or len(vlist) < n: 
        return "", ""
    v = vlist[n-1]
    return v.get("title","video"), v.get("url","")

titles1, urls1, titles2, urls2, titles3, urls3 = [], [], [], [], [], []
for vs in f["matches"].tolist():
    t1, u1 = nth_link(vs, 1)
    t2, u2 = nth_link(vs, 2)
    t3, u3 = nth_link(vs, 3)
    titles1.append(t1); urls1.append(u1)
    titles2.append(t2); urls2.append(u2)
    titles3.append(t3); urls3.append(u3)

f = f.drop(columns=["matches", "_idx", "aliases"])
f["ì˜ìƒ1 ì œëª©"] = titles1; f["ì˜ìƒ1"] = urls1
f["ì˜ìƒ2 ì œëª©"] = titles2; f["ì˜ìƒ2"] = urls2
f["ì˜ìƒ3 ì œëª©"] = titles3; f["ì˜ìƒ3"] = urls3

# í‘œì‹œ ì»¬ëŸ¼ ì„ íƒ/ì •ë ¬
base_cols = ["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…"]
video_cols = ["ì˜ìƒ1 ì œëª©","ì˜ìƒ1","ì˜ìƒ2 ì œëª©","ì˜ìƒ2","ì˜ìƒ3 ì œëª©","ì˜ìƒ3"]
ordered = []
for c in ["ì•½ì(ì•½ì–´)", "ìš©ì–´(ì˜ë¬¸)", "í•œêµ­ì–´", "ì„¤ëª…", "ì˜ìƒ1", "ì˜ìƒ2", "ì˜ìƒ3"]:
    if c in ["ì˜ìƒ1","ì˜ìƒ2","ì˜ìƒ3"]:
        # ì œëª©-ë§í¬ ìŒì„ í‘œì— í•¨ê»˜ ë³´ì—¬ì£¼ê³  ì‹¶ìœ¼ë©´ ì œëª© ì»¬ëŸ¼ë„ í¬í•¨
        idx = int(c[-1])
        tcol = f"ì˜ìƒ{idx} ì œëª©"
        if tcol not in ordered: ordered.append(tcol)
        if c not in ordered: ordered.append(c)
    else:
        if c not in ordered: ordered.append(c)

# ìµœì¢… í‘œ
table = f[ordered].copy()

# ğŸ”— ë§í¬ê°€ í‘œì—ì„œ ë°”ë¡œ í´ë¦­ë˜ë„ë¡ LinkColumn ì‚¬ìš©
link_cfg = {
    "ì˜ìƒ1": st.column_config.LinkColumn("ì˜ìƒ1", display_text="ì—´ê¸°"),
    "ì˜ìƒ2": st.column_config.LinkColumn("ì˜ìƒ2", display_text="ì—´ê¸°"),
    "ì˜ìƒ3": st.column_config.LinkColumn("ì˜ìƒ3", display_text="ì—´ê¸°"),
}

# í‘œì‹œí•  ì—´ë§Œ í•„í„°
table = table[[c for c in ordered if c in show_cols or c.startswith("ì˜ìƒ") and c.replace(" ì œëª©","") in show_cols]]

st.write(f"ê²€ìƒ‰ ê²°ê³¼: **{len(table)}**ê°œ")
st.dataframe(table, use_container_width=True, hide_index=True, column_config=link_cfg)

st.divider()
st.caption("â€» â€˜ì˜ìƒ1/2/3â€™ì€ ì œê³µëœ ì¬ìƒëª©ë¡ì—ì„œ ì œëª©-í‚¤ì›Œë“œë¡œ ìë™ ë§¤ì¹­ëœ ê°œë³„ ì˜ìƒì…ë‹ˆë‹¤. í•„ìš”ì‹œ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ìƒëª©ë¡ì„ ë°”ê¾¸ê³  â€˜ë¶ˆëŸ¬ì˜¤ê¸°â€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê°±ì‹ í•˜ì„¸ìš”.")